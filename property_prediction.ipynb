{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/m275696/.conda/envs/ftudd_chem\n",
      "\n",
      "  added / updated specs:\n",
      "    - boost\n",
      "    - boost-cpp\n",
      "    - descriptastorus\n",
      "    - jupyterlab\n",
      "    - numpy\n",
      "    - numpy-base\n",
      "    - pandas\n",
      "    - python\n",
      "    - pytorch\n",
      "    - rdkit\n",
      "    - readline\n",
      "    - scikit-learn\n",
      "    - scipy\n",
      "    - tensorboard\n",
      "    - torchvision\n",
      "    - tqdm\n",
      "    - transformers\n",
      "    - typing\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_llvm\n",
      "  absl-py            conda-forge/noarch::absl-py-1.0.0-pyhd8ed1ab_0\n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.8.1-py37h5e8e339_0\n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.2.0-pyhd8ed1ab_0\n",
      "  anyio              conda-forge/linux-64::anyio-3.5.0-py37h89c1867_0\n",
      "  argon2-cffi        conda-forge/noarch::argon2-cffi-21.3.0-pyhd8ed1ab_0\n",
      "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py37h5e8e339_1\n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0\n",
      "  asynctest          conda-forge/noarch::asynctest-0.13.0-py_0\n",
      "  attrs              conda-forge/noarch::attrs-21.4.0-pyhd8ed1ab_0\n",
      "  babel              conda-forge/noarch::babel-2.9.1-pyh44b312d_0\n",
      "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0\n",
      "  backports          conda-forge/noarch::backports-1.0-py_2\n",
      "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.4-pyhd8ed1ab_0\n",
      "  blas               conda-forge/linux-64::blas-2.3-openblas\n",
      "  bleach             conda-forge/noarch::bleach-4.1.0-pyhd8ed1ab_0\n",
      "  blinker            conda-forge/noarch::blinker-1.4-py_1\n",
      "  boost              conda-forge/linux-64::boost-1.68.0-py37h8619c78_1001\n",
      "  boost-cpp          conda-forge/linux-64::boost-cpp-1.68.0-h11c811c_1000\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py37h5e8e339_1003\n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
      "  c-ares             conda-forge/linux-64::c-ares-1.18.1-h7f98852_0\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2021.10.8-ha878542_0\n",
      "  cachetools         conda-forge/noarch::cachetools-5.0.0-pyhd8ed1ab_0\n",
      "  cairo              conda-forge/linux-64::cairo-1.16.0-h18b612c_1001\n",
      "  certifi            conda-forge/linux-64::certifi-2021.10.8-py37h89c1867_1\n",
      "  cffi               conda-forge/linux-64::cffi-1.15.0-py37h036bc23_0\n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-2.0.12-pyhd8ed1ab_0\n",
      "  click              conda-forge/linux-64::click-8.0.4-py37h89c1867_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  cryptography       conda-forge/linux-64::cryptography-36.0.1-py37hf1a17b8_0\n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.1.243-h036e899_10\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\n",
      "  debugpy            conda-forge/linux-64::debugpy-1.5.1-py37hcd2ae1e_0\n",
      "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0\n",
      "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
      "  descriptastorus    rmg/noarch::descriptastorus-2.2.0-py_0\n",
      "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0\n",
      "  filelock           conda-forge/noarch::filelock-3.6.0-pyhd8ed1ab_0\n",
      "  flit-core          conda-forge/noarch::flit-core-3.7.1-pyhd8ed1ab_0\n",
      "  fontconfig         conda-forge/linux-64::fontconfig-2.13.96-ha180cfb_0\n",
      "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.3.0-py37h5e8e339_0\n",
      "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h73d1719_1008\n",
      "  glib               conda-forge/linux-64::glib-2.70.2-h780b84a_4\n",
      "  glib-tools         conda-forge/linux-64::glib-tools-2.70.2-h780b84a_4\n",
      "  google-auth        conda-forge/noarch::google-auth-2.6.0-pyh6c4a22f_1\n",
      "  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-0.4.6-pyhd8ed1ab_0\n",
      "  grpcio             conda-forge/linux-64::grpcio-1.44.0-py37hb27c1af_0\n",
      "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.4.0-pyhd8ed1ab_0\n",
      "  icu                conda-forge/linux-64::icu-58.2-hf484d3e_1000\n",
      "  idna               conda-forge/noarch::idna-3.3-pyhd8ed1ab_0\n",
      "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.11.2-py37h89c1867_0\n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-4.11.2-hd8ed1ab_0\n",
      "  importlib_resourc~ conda-forge/noarch::importlib_resources-5.4.0-pyhd8ed1ab_0\n",
      "  ipykernel          conda-forge/linux-64::ipykernel-6.9.1-py37h6531663_0\n",
      "  ipython            conda-forge/linux-64::ipython-7.32.0-py37h89c1867_0\n",
      "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
      "  jedi               conda-forge/linux-64::jedi-0.18.1-py37h89c1867_0\n",
      "  jinja2             conda-forge/noarch::jinja2-3.0.3-pyhd8ed1ab_0\n",
      "  joblib             conda-forge/noarch::joblib-1.1.0-pyhd8ed1ab_0\n",
      "  jpeg               conda-forge/linux-64::jpeg-9e-h7f98852_0\n",
      "  json5              conda-forge/noarch::json5-0.9.5-pyh9f0ad1d_0\n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.4.0-pyhd8ed1ab_0\n",
      "  jupyter_client     conda-forge/noarch::jupyter_client-7.1.2-pyhd8ed1ab_0\n",
      "  jupyter_core       conda-forge/linux-64::jupyter_core-4.9.2-py37h89c1867_0\n",
      "  jupyter_server     conda-forge/noarch::jupyter_server-1.13.5-pyhd8ed1ab_1\n",
      "  jupyterlab         conda-forge/noarch::jupyterlab-3.3.0-pyhd8ed1ab_0\n",
      "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.1.2-pyh9f0ad1d_0\n",
      "  jupyterlab_server  conda-forge/noarch::jupyterlab_server-2.10.3-pyhd8ed1ab_0\n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.36.1-hea4e1c9_2\n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-3_openblas\n",
      "  libboost           pkgs/main/linux-64::libboost-1.73.0-h3ff78a5_11\n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-3_openblas\n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5\n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-11.2.0-h1d223b6_13\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-h14aa051_20\n",
      "  libgfortran4       conda-forge/linux-64::libgfortran4-7.5.0-h14aa051_20\n",
      "  libglib            conda-forge/linux-64::libglib-2.70.2-h174f98d_4\n",
      "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-3_openblas\n",
      "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-3_openblas\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.12-pthreads_hb3c22a3_1\n",
      "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.19.4-h780b84a_0\n",
      "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1\n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-11.2.0-he4da1e4_13\n",
      "  libtiff            conda-forge/linux-64::libtiff-4.0.10-hc3755c2_1005\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
      "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004\n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.9.12-h03d6c58_0\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.11-h36c2ea0_1013\n",
      "  llvm-openmp        conda-forge/linux-64::llvm-openmp-13.0.1-he0ac6c6_1\n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_1\n",
      "  markdown           conda-forge/noarch::markdown-3.3.6-pyhd8ed1ab_0\n",
      "  markupsafe         conda-forge/linux-64::markupsafe-2.1.0-py37h540881e_0\n",
      "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.3-pyhd8ed1ab_0\n",
      "  mistune            conda-forge/linux-64::mistune-0.8.4-py37h5e8e339_1005\n",
      "  mkl                conda-forge/linux-64::mkl-2022.0.1-h8d4b97c_803\n",
      "  multidict          conda-forge/linux-64::multidict-6.0.2-py37h5e8e339_0\n",
      "  nbclassic          conda-forge/noarch::nbclassic-0.3.5-pyhd8ed1ab_0\n",
      "  nbclient           conda-forge/noarch::nbclient-0.5.11-pyhd8ed1ab_0\n",
      "  nbconvert          conda-forge/linux-64::nbconvert-6.4.2-py37h89c1867_0\n",
      "  nbformat           conda-forge/noarch::nbformat-5.1.3-pyhd8ed1ab_0\n",
      "  ncurses            conda-forge/linux-64::ncurses-6.3-h9c3ff4c_0\n",
      "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.4-pyhd8ed1ab_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.2-h4bd325d_1\n",
      "  notebook           conda-forge/noarch::notebook-6.4.8-pyha770c72_0\n",
      "  numpy              conda-forge/linux-64::numpy-1.20.3-py37h038b26d_0\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.18.5-py37h2f8d375_0\n",
      "  oauthlib           conda-forge/noarch::oauthlib-3.2.0-pyhd8ed1ab_0\n",
      "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
      "  openssl            conda-forge/linux-64::openssl-1.1.1l-h7f98852_0\n",
      "  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n",
      "  pandas             conda-forge/linux-64::pandas-1.3.5-py37he8f5f7f_0\n",
      "  pandoc             conda-forge/linux-64::pandoc-2.17.1.1-ha770c72_0\n",
      "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0\n",
      "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0\n",
      "  pcre               conda-forge/linux-64::pcre-8.45-h9c3ff4c_0\n",
      "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh9f0ad1d_2\n",
      "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003\n",
      "  pillow             conda-forge/linux-64::pillow-6.2.1-py37h6b7be26_0\n",
      "  pip                conda-forge/noarch::pip-22.0.3-pyhd8ed1ab_0\n",
      "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
      "  prometheus_client  conda-forge/noarch::prometheus_client-0.13.1-pyhd8ed1ab_0\n",
      "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.27-pyha770c72_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.19.4-py37hcd2ae1e_0\n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
      "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0\n",
      "  py-boost           pkgs/main/linux-64::py-boost-1.73.0-py37ha9443f7_11\n",
      "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\n",
      "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\n",
      "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0\n",
      "  pygments           conda-forge/noarch::pygments-2.11.2-pyhd8ed1ab_0\n",
      "  pyjwt              conda-forge/noarch::pyjwt-2.3.0-pyhd8ed1ab_1\n",
      "  pyopenssl          conda-forge/noarch::pyopenssl-22.0.0-pyhd8ed1ab_0\n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.0.7-pyhd8ed1ab_0\n",
      "  pyrsistent         conda-forge/linux-64::pyrsistent-0.18.1-py37h5e8e339_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-py37h89c1867_4\n",
      "  python             conda-forge/linux-64::python-3.7.12-hb7a2778_100_cpython\n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.7-2_cp37m\n",
      "  pytorch            pytorch/linux-64::pytorch-1.4.0-py3.7_cuda10.1.243_cudnn7.6.3_0\n",
      "  pytz               conda-forge/noarch::pytz-2021.3-pyhd8ed1ab_0\n",
      "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0-py37h5e8e339_3\n",
      "  pyzmq              conda-forge/linux-64::pyzmq-22.3.0-py37h336d617_1\n",
      "  rdkit              rdkit/linux-64::rdkit-2020.09.1.0-py37hd50e099_1\n",
      "  readline           conda-forge/linux-64::readline-8.1-h46c0cb4_0\n",
      "  regex              conda-forge/linux-64::regex-2022.3.2-py37h540881e_0\n",
      "  requests           conda-forge/noarch::requests-2.27.1-pyhd8ed1ab_0\n",
      "  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.1-pyhd8ed1ab_0\n",
      "  rsa                conda-forge/noarch::rsa-4.8-pyhd8ed1ab_0\n",
      "  sacremoses         conda-forge/noarch::sacremoses-0.0.46-pyhd8ed1ab_0\n",
      "  scikit-learn       conda-forge/linux-64::scikit-learn-1.0.2-py37hf9e9bfc_0\n",
      "  scipy              conda-forge/linux-64::scipy-1.5.3-py37h8911b10_0\n",
      "  send2trash         conda-forge/noarch::send2trash-1.8.0-pyhd8ed1ab_0\n",
      "  setuptools         conda-forge/linux-64::setuptools-59.8.0-py37h89c1867_0\n",
      "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0\n",
      "  sniffio            conda-forge/linux-64::sniffio-1.2.0-py37h89c1867_2\n",
      "  sqlite             conda-forge/linux-64::sqlite-3.37.0-h9cd32fc_0\n",
      "  tbb                conda-forge/linux-64::tbb-2021.5.0-h4bd325d_0\n",
      "  tensorboard        conda-forge/noarch::tensorboard-2.8.0-pyhd8ed1ab_1\n",
      "  tensorboard-data-~ conda-forge/linux-64::tensorboard-data-server-0.6.0-py37hf1a17b8_1\n",
      "  tensorboard-plugi~ conda-forge/noarch::tensorboard-plugin-wit-1.8.1-pyhd8ed1ab_0\n",
      "  terminado          conda-forge/linux-64::terminado-0.13.2-py37h89c1867_0\n",
      "  testpath           conda-forge/noarch::testpath-0.6.0-pyhd8ed1ab_0\n",
      "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.1.0-pyh8a188c0_0\n",
      "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0\n",
      "  tokenizers         pkgs/main/linux-64::tokenizers-0.10.3-py37hb317417_1\n",
      "  torchvision        pytorch/linux-64::torchvision-0.5.0-py37_cu101\n",
      "  tornado            conda-forge/linux-64::tornado-6.1-py37h5e8e339_2\n",
      "  tqdm               conda-forge/noarch::tqdm-4.63.0-pyhd8ed1ab_0\n",
      "  traitlets          conda-forge/noarch::traitlets-5.1.1-pyhd8ed1ab_0\n",
      "  transformers       conda-forge/noarch::transformers-4.16.2-pyhd8ed1ab_0\n",
      "  typing             conda-forge/noarch::typing-3.10.0.0-pyhd8ed1ab_0\n",
      "  typing-extensions  conda-forge/noarch::typing-extensions-4.1.1-hd8ed1ab_0\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.1.1-pyha770c72_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.8-pyhd8ed1ab_1\n",
      "  wcwidth            conda-forge/noarch::wcwidth-0.2.5-pyh9f0ad1d_2\n",
      "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.3.1-pyhd8ed1ab_0\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.0.3-pyhd8ed1ab_1\n",
      "  wheel              conda-forge/noarch::wheel-0.37.1-pyhd8ed1ab_0\n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.2-h7f98852_0\n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
      "  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_1\n",
      "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2\n",
      "  yarl               conda-forge/linux-64::yarl-1.7.2-py37h5e8e339_1\n",
      "  zeromq             conda-forge/linux-64::zeromq-4.3.4-h9c3ff4c_1\n",
      "  zipp               conda-forge/noarch::zipp-3.7.0-pyhd8ed1ab_1\n",
      "  zlib               conda-forge/linux-64::zlib-1.2.11-h36c2ea0_1013\n",
      "  zstd               conda-forge/linux-64::zstd-1.4.9-ha95c52a_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate ftudd_chem\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -n ftudd_chem --file requirements_chem.txt -c pytorch -c rdkit -c conda-forge -c rmg -y\n",
    "# This will take a couple of minutes.\n",
    "# After installation is finished start the notebook in the new environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grover model\n",
    "\n",
    "Code and pretrained weights are available from here: https://github.com/tencent-ailab/grover. We will use a fork of it where I already fixed a bug in the code base.\n",
    "\n",
    "Implementation of Yu et al., Self-Supervised Graph Transformer on Large-Scale Molecular Data, NeurIPS 2020\n",
    "\n",
    "Grover is an instance of a graph neural network. It is trained in a self-supervised way, i.e. from unlabeled training data, and creates an embedding of a molecule. It can be fine-tuned for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '../grover'...\n",
      "remote: Enumerating objects: 76, done.\u001b[K\n",
      "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
      "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
      "remote: Total 76 (delta 14), reused 61 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (76/76), done.\n",
      "--2022-03-04 12:57:50--  https://ai.tencent.com/ailab/ml/ml-data/grover-models/pretrain/grover_large.tar.gz\n",
      "Resolving ai.tencent.com (ai.tencent.com)... 116.128.164.87\n",
      "Connecting to ai.tencent.com (ai.tencent.com)|116.128.164.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399013496 (381M) [application/octet-stream]\n",
      "Saving to: ‘../grover/data/grover_large.tar.gz’\n",
      "\n",
      "../grover/data/grov 100%[===================>] 380.53M  5.35MB/s    in 83s     \n",
      "\n",
      "2022-03-04 12:59:14 (4.61 MB/s) - ‘../grover/data/grover_large.tar.gz’ saved [399013496/399013496]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clone Grover repository\n",
    "!git clone https://github.com/emdgroup/grover.git ../grover\n",
    "!mkdir ../grover/data/\n",
    "!wget https://ai.tencent.com/ailab/ml/ml-data/grover-models/pretrain/grover_large.tar.gz -O ../grover/data/grover_large.tar.gz\n",
    "!tar -xzf ../grover/data/grover_large.tar.gz -C ../grover/data/\n",
    "sys.path.append('../grover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grover has a command line interface, let us use it to generate an embedding of a sample molecule\n",
    "import pandas as pd\n",
    "smiles = ['CC(=O)O', 'CCCCCC']\n",
    "pd.DataFrame({'SMILES': smiles}).to_csv('test_smiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "100%|██████████| 2/2 [00:00<00:00, 34.99it/s]\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "Total size = 2\n",
      "Generating...\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
      "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
      "Moving model to cuda\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python ../grover/scripts/save_features.py --data_path test_smiles.csv --save_path test_features.npz --features_generator rdkit_2d_normalized --restart \n",
    "python ../grover/main.py fingerprint --data_path test_smiles.csv --features_path test_features.npz --checkpoint_path ../grover/data/grover_large.pt --fingerprint_source both --output test_fingerprints.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.3896969e-02  3.3971572e-01 -3.9031762e-01 ...  4.7035982e-08\n",
      "   1.6663340e-01  2.6578519e-01]\n",
      " [-2.4661005e-01  1.2936553e-01  7.6430368e-01 ...  9.6070671e-01\n",
      "   1.6663340e-01  3.0714130e-01]]\n",
      "(2, 5000)\n"
     ]
    }
   ],
   "source": [
    "# load the fingerprints\n",
    "import numpy as np\n",
    "fingerprints = np.load('test_fingerprints.npz')[\"fps\"]\n",
    "print(fingerprints)\n",
    "print(fingerprints.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChemBERTa model\n",
    "\n",
    "ChemBERTa is based on the BERT NLP model and treats SMILES strings as text that can be modeled. Most NLP models are nicely wrapped by the Huggingface transformer library and hence, we can leverage their API. Further details on ChemBERTa can be found in the paper:\n",
    "\n",
    "Chithrananda et al., ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction, arXiv 2020\n",
    "\n",
    "or at Github: https://github.com/seyonechithrananda/bert-loves-chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Chemberta model\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "chemberta_model_name = 'seyonec/ChemBERTa-zinc-base-v1'\n",
    "chemberta_tokenizer = AutoTokenizer.from_pretrained(chemberta_model_name)\n",
    "chemberta_model = AutoModelForMaskedLM.from_pretrained(chemberta_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "[ 0.30163023  0.50087255 -0.67029685 -1.5062698   0.09748616 -0.6335993\n",
      " -0.02147115  0.14238326 -1.3668206   0.44067818]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def embed_smiles(smiles, tokenizer, model, layers):\n",
    "    \"\"\"\n",
    "    Returns the embedding of a SMILES string.\n",
    "    \"\"\"\n",
    "    # Get the tokenized input\n",
    "    tokenized_input = tokenizer(smiles, return_tensors='pt')\n",
    "    # Get the embedding\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized_input, output_hidden_states=True)\n",
    "    # Return the embedding\n",
    "    states = torch.stack([output.hidden_states[l] for l in layers]).mean([1,2]).view(-1)\n",
    "    return states.detach().numpy()\n",
    "\n",
    "test_embedding = embed_smiles('CC(=O)O', chemberta_tokenizer, chemberta_model, [-1])\n",
    "print(test_embedding.shape)\n",
    "print(test_embedding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AqSolDB data \n",
    "import pandas as pd\n",
    "df_aqsol = pd.read_csv('curated-solubility-dataset.csv')\n",
    "print(df_aqsol.head(4))\n",
    "smiles = df_aqsol['SMILES'].values\n",
    "targets = df_aqsol['Solubility'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your tasks\n",
    "1. Create embeddings for the molecules in the AqSolDB dataset using both the pretrained ChemBERTa model as well as the Grover model\n",
    "2. Train a suitable scikit-learn model on top of these embeddings to predict the solubility\n",
    "3. Experiment with this setting and summarize your findings\n",
    "\n",
    "### The advanced stuff\n",
    "4. Fine tune Grover and ChemBERTa on the AqSol prediction task \n",
    "5. Experiment and summarize your findings\n",
    "For fine-tuning Grover have a look at their Github page. For fine-tuning a language model from Huggingface, see here: https://huggingface.co/docs/transformers/training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
