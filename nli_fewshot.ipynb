{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you opened the notebook in Colab\n",
    "!wget https://raw.githubusercontent.com/tobiasploetz-merck/ftudd_deeplearning/main/requirements_transformers.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements_transformers.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m275696/.conda/envs/nli/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use Natural Language Inference (NLI)\n",
    "(based off https://huggingface.co/facebook/bart-large-mnli)\n",
    "We will use a model that is trained to take two text inputs. The first is a premise, the second is the hypothesis. The model outputs the probability for three classes: 1) the hypothesis is supported by the premise, 2) the premise does not allow inference about the truth of the hypothesis, and 3) the premise contradicts the hypothesis. These kind of models can be used to do zero-shot classification. Below, we will use a ready-made wrapper from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'These are busy times in the White House with the president in constant negotiations with the senate.',\n",
       " 'labels': ['politics', 'business', 'sports'],\n",
       " 'scores': [0.7993637323379517, 0.1540120244026184, 0.046624280512332916]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=0 if torch.cuda.is_available() else -1)\n",
    "sequence_to_classify = \"These are busy times in the White House with the president in constant negotiations with the senate.\"\n",
    "candidate_labels = ['business', 'sports', 'politics']\n",
    "classifier(sequence_to_classify, candidate_labels, hypothesis_template=\"This example is about {}\")\n",
    "# Note that scores are already sorted and hence the labels field has a different order than the candidate_labels variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/m275696/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 531.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n",
      "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])\n",
    "# labels are 0: World, 1: Sports, 2: Business, 3: Science&Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your tasks\n",
    "\n",
    "Part 1 (NLI):\n",
    "1. Get familiar with NLI. Try it on a few example premises and set of classes. Try different templates for the hypothesis. \n",
    "2. Use NLI on a suitably sized subset of the AG News testset. Report the accuracy. Try to tune the hypothesis template on a small subset of the training set. Try to think of other ways to improve accuracy\n",
    "3. Summarize and report your findings.\n",
    "\n",
    "Part 2 (Few-Shot fine-tuning):\n",
    "1. Read through the tutorial here: https://huggingface.co/docs/transformers/custom_datasets\n",
    "2. Use the facebook/bart-large model to fine tune on a random subset of the training data (https://huggingface.co/facebook/bart-large)\n",
    "3. Evaluate the model performance on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81e4e1a49398efdf063f6cbf08dbdc49f7843078b03fcfbaf9340c23a7972ea2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('nli')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
